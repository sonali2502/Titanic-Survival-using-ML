{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np                 #data processing :  numpy , pandas\n",
    "import pandas as pd                 \n",
    "import matplotlib.pyplot as plt # data visualization: matplotlib,seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/vinod.sharma1/Desktop/titanic.csv'\n",
    "titanic = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head() #   method, Pclass: Passenger class, SibSp: no.of sibling or Spouse travelling \n",
    "               #   along, Parch: parent/children travelling along, NaN: not a number,\n",
    "               #   Embarked: place from where they boardedthe ship\n",
    "               #   Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.tail()# method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape # shape: attribute, gives the count of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info() # Age,Cabin,Embarked: values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull() # True: Null(no value), False: Not null(contains value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum() #missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(titanic.isnull().sum())  #missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization: Visualizing using the count of rows as range to see the missing data\n",
    "# Wherever there is a gap that denotes the missing values\n",
    "sns.heatmap(titanic.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A heat map (or heatmap) is a data visualization technique that shows magnitude of a \n",
    "# phenomenon as color in two dimensions. The variation in color may be by hue or intensity, \n",
    "# giving obvious visual cues to the reader about how the phenomenon is clustered or varies\n",
    "# over space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap is a graphical way to visualize visitor behavior data in the form of hot and cold \n",
    "# spots employing a warm-to-cool color scheme. The warm colors indicated sections with the\n",
    "# most visitor interaction, red being the area of highest interaction, and the cool colors \n",
    "# indicate sections with the lowest interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing colour of heatmap\n",
    "sns.heatmap(titanic.isnull(),cmap='viridis') #cmap: adjusts colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(titanic.isnull(),cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(titanic.isnull(),cmap='cividis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot: Show the counts of observations in each categorical bin using bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived',data = titanic) # it depicts that more people died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hue is used to divide the result on the basis of some attribute.\n",
    "# survived--no.  (always)\n",
    "# hue---non no. (always)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived' , data=titanic , hue='Sex')\n",
    "# In case of died people: more men died as compared to women\n",
    "# In case of alive: more women survived as compared to men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived' , data=titanic , hue='Pclass')\n",
    "# died: mostly people belonging to 3rd class died\n",
    "# alive: mostly people from 1st class survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sex',data=titanic) # it shows more man went on the ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived',data=titanic,hue='Embarked') # it shows people that board the \n",
    "# ship from 's' died max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='SibSp',data=titanic) # It shows maximum people travelled alone and how many \n",
    "# people took either their sibling or their spouse along with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Parch',data=titanic) # It shows maximum people travelled alone and how many \n",
    "# people took either their parent or their children along with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distplot lets you show a histogram with a line on it , histogram is used when we want to \n",
    "# show some attribute within a particular range and if you want to remove the line that comes,\n",
    "# when an hist is created then you need to set the kernel distribution, kde to false, i.e, \n",
    "# kde=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic['Age'],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic['Fare'],kde=False,bins=30)\n",
    "#  bins are the vertical columns, general range: 25-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic['Fare'],kde=False,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning means filtering and modifying your data such that it is easier to explore, \n",
    "# understand, and model. Filtering out the parts you don't want or need so that you don't need\n",
    "# to look at or process them.\n",
    "# The main aim of Data Cleaning is to identify and remove errors & duplicate data, in order to \n",
    "# create a reliable dataset. This improves the quality of the training data for analytics and \n",
    "# enables accurate decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values can be imputed/filled with a provided constant value or using the statistics \n",
    "# (mean, median or most frequent) of each column in which the missing values are located. \n",
    "# Age imputation\n",
    "sns.boxplot(x='Pclass', y='Age', data=titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A box plot is a method for graphically depicting groups of numerical data through their \n",
    "#quartiles. The box extends from the Q1 to Q3 quartile values of the data, with a line at the \n",
    "#median (Q2). The whiskers extend from the edges of box to show the range of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(cols):\n",
    "    age = cols[0]\n",
    "    pclass =cols[1]\n",
    "    \n",
    "    if pd.isnull(age):\n",
    "        if pclass ==1:\n",
    "            return 37\n",
    "        elif pclass ==2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 27\n",
    "    else:\n",
    "        return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'] = titanic[['Age','Pclass']].apply(impute_age,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age imputation\n",
    "\n",
    "# creating func impute_age, dataframe will be created.cols is df axis=1, \n",
    "# tells you need to apply on columns else will apply on rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(titanic.isnull(),cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop('Cabin',axis=1,inplace=True)\n",
    "# inplace=True, so that whatever changes we are doing it must update the \n",
    "# original data also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(titanic.isnull(),cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Embarked',data=titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_imput(cols):\n",
    "    emb=cols[0]\n",
    "    pclass=cols[1]\n",
    "    \n",
    "    if pd.isnull(emb):\n",
    "        if pclass==1 or pclass==2 or  pclass==3: \n",
    "            return 'S'\n",
    "    else:\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Embarked'] = titanic[['Embarked','Pclass']].apply(emb_imput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(titanic.isnull(),cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns which are not contributing in the analysis and are of no use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['Name','Ticket','PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex and embarked(S,C,Q) are in character form , so refine the data and convert them into no.s\n",
    "# by first creating their dummies and then removing them from the original data and combining \n",
    "# the data with their dummies value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(titanic['Sex'],drop_first=True)\n",
    "embark = pd.get_dummies(titanic['Embarked'],drop_first=True)\n",
    "# drop_first: bool,  by default = False\n",
    "# Whether to get k-1 dummies out of k categorical levels by removing the first level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['Sex','Embarked'],axis = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.concat([titanic,sex,embark],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning: Dividing the data into 3 parts\n",
    "\n",
    "X = titanic.drop('Survived',axis = 1)\n",
    "Y = titanic['Survived']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.30)\n",
    "\n",
    "# x_train is the training data set(that includes features). y_train is the set of labels to \n",
    "# all the data in x_train .\n",
    "\n",
    "# test_size — This parameter decides the size of the data that has to be split as the test \n",
    "# dataset. This is given as a fraction. For example, if you pass 0.5 as the value, the dataset \n",
    "# will be split 50% as the test dataset.\n",
    "\n",
    "# The training set is a subset of the data set used to train a model.\n",
    "# x_train is the training data set. y_train is the set of labels to all the data in x_train.\n",
    "# The test set is a subset of the data set that you use to test your model after the model has \n",
    "# gone through initial vetting by the validation set.\n",
    "\n",
    "# x_test is the test data set.y_test is the set of labels to all the data in x_test.\n",
    "# The validation set is a subset of the data set (separate from the training set) that you use \n",
    "# to adjust hyperparameters.\n",
    "\n",
    "# A hyperparameter is a parameter whose value is set before the learning process begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       178\n",
      "           1       0.69      0.71      0.70        90\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.77      0.77      0.77       268\n",
      "weighted avg       0.80      0.79      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
